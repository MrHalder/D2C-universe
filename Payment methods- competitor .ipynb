{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8951b50d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "baee07f1",
   "metadata": {},
   "source": [
    "### Press shift + Enter to execute the cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd99ebc",
   "metadata": {},
   "source": [
    "### your csv should contain column name as website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a86ae25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ea2be3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_https(url):\n",
    "    if not url.startswith('https://') and not url.startswith('http://'):\n",
    "        return 'https://' + url\n",
    "    else:\n",
    "        return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e61717e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def payment_methods_available(possible_values):\n",
    "    payment_methods = []\n",
    "    for value in possible_values:\n",
    "        if 'gokwik' in value.lower():\n",
    "            payment_methods.append('GoKwik')\n",
    "        if 'simpl' in value.lower():\n",
    "            payment_methods.append('Simpl')\n",
    "        if 'zecpe' in value.lower():\n",
    "            payment_methods.append('Zecpe')\n",
    "        if 'snapmint' in value.lower():\n",
    "            payment_methods.append('Snapmint')\n",
    "        if 'magic-rzp' in value.lower():\n",
    "            payment_methods.append('Razorpay Magic')\n",
    "    return list(set(payment_methods))\n",
    "\n",
    "# Apply the functions to create new columns\n",
    "#df['extracted_values'] = df.apply(extract_values, axis=1)\n",
    "\n",
    "\n",
    "#df['payment_method_availabe_possible'] = df['extracted_values'].apply(payment_methods_available)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea171ae",
   "metadata": {},
   "source": [
    "### The main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0247a82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getting_payment_info(csv_file):\n",
    "\n",
    "    # List of URLs to inspect\n",
    "    urls = pd.read_csv(csv_file)\n",
    "    urls = urls[urls['website'].notnull()]\n",
    "    urls['website'] = urls['website'].astype('str')\n",
    "    urls['website'] = urls['website'].apply(add_https)\n",
    "    urls_to_inspect = urls['website']  # Replace with your actual URLs\n",
    "\n",
    "    # Initialize an empty DataFrame\n",
    "    df = pd.DataFrame(columns=['url', 's1', 's2', 'js_set', 'begin_keywords'])\n",
    "\n",
    "    i = 0\n",
    "    for url in urls_to_inspect:\n",
    "        print(i)\n",
    "        try:\n",
    "            # Send an HTTP GET request to the URL with a timeout of 10 seconds\n",
    "            response = requests.get(url, timeout=10)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                # Get the page source\n",
    "                page_source = response.text\n",
    "\n",
    "                # Use regular expressions to find all subdomains (without 'cdn')\n",
    "                subdomains = re.findall(r'(https?://[a-zA-Z0-9.-]+\\.[a-z]+)', page_source)\n",
    "                subdomains_2 = re.findall(r'(https?://[a-zA-Z0-9.-]*cdn[a-zA-Z0-9.-]*\\.[a-z]+)', page_source)\n",
    "                s1 = list(set(subdomains))\n",
    "                s2 = list(set(subdomains_2))\n",
    "\n",
    "                # Use BeautifulSoup to parse the HTML content\n",
    "                soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "                # Find all script tags with the specified pattern\n",
    "                script_pattern = re.compile(r'<script[^>]*src=[\\'\"]([^\\'\"]*\\.js)[\\'\"][^>]*>', re.IGNORECASE)\n",
    "                js_set = list(set(script_pattern.findall(str(soup))))\n",
    "\n",
    "                # Use regular expressions to find 'begin' related keywords in HTML comments\n",
    "                comment_pattern = r'<!--(.*?)-->'\n",
    "                search_keyword = 'begin'\n",
    "                exclude_keyword = 'snippet'\n",
    "                matches = re.finditer(comment_pattern, page_source, re.DOTALL | re.IGNORECASE)\n",
    "                begin_keywords = [match.group(1) for match in matches if search_keyword.lower() in match.group(1).lower() and exclude_keyword not in match.group(1).lower()]\n",
    "\n",
    "            else:\n",
    "                # If the response status code is not 200, set all columns (except 'URL') to lists with 'NA'\n",
    "                s1 = ['NA']\n",
    "                s2 = ['NA']\n",
    "                js_set = ['NA']\n",
    "                begin_keywords = ['NA']\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Exception occurred for URL {url}: {e}\")\n",
    "            # Set values to handle the exception\n",
    "            s1 = ['Exception']\n",
    "            s2 = ['Exception']\n",
    "            js_set = ['Exception']\n",
    "            begin_keywords = ['Exception']\n",
    "\n",
    "        i += 1\n",
    "\n",
    "        # Create a dictionary with the data for the current URL\n",
    "        data = {\n",
    "            'url': [url],\n",
    "            's1': [s1],\n",
    "            's2': [s2],\n",
    "            'js_set': [js_set],\n",
    "            'begin_keywords': [begin_keywords],\n",
    "        }\n",
    "\n",
    "        # Append the data to the DataFrame\n",
    "        df = pd.concat([df, pd.DataFrame(data)], ignore_index=True)\n",
    "        combined_values = df['s1'] + df['s2']+ df['js_set']+ df['begin_keywords']\n",
    "        urls['payment_method_available_possible'] = combined_values.apply(payment_methods_available)\n",
    "    \n",
    "    return urls\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b306a15d",
   "metadata": {},
   "source": [
    "### below is just an example of how your csv should look ( the only imp thing is that the column name should be 'website'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a03565d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Suger candy</td>\n",
       "      <td>sugercandy.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Radha Mohan Enterprises</td>\n",
       "      <td>sircorbett.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PinkWoolf</td>\n",
       "      <td>pinkwoolf.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shriya Singhi Label</td>\n",
       "      <td>shriyasinghi.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISU</td>\n",
       "      <td>isufashion.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3510</th>\n",
       "      <td>Bombay Greens</td>\n",
       "      <td>Www.bombaygreens.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3511</th>\n",
       "      <td>uncletony</td>\n",
       "      <td>uncletony.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3512</th>\n",
       "      <td>The Indian Garage</td>\n",
       "      <td>https://tigc.in/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3513</th>\n",
       "      <td>Lipka Home</td>\n",
       "      <td>https://lipkahome.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3514</th>\n",
       "      <td>NestInPeace</td>\n",
       "      <td>https://www.nestinpeace.in/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3515 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Name                      website\n",
       "0                 Suger candy               sugercandy.com\n",
       "1     Radha Mohan Enterprises               sircorbett.com\n",
       "2                   PinkWoolf                pinkwoolf.com\n",
       "3         Shriya Singhi Label             shriyasinghi.com\n",
       "4                         ISU               isufashion.com\n",
       "...                       ...                          ...\n",
       "3510            Bombay Greens         Www.bombaygreens.com\n",
       "3511                uncletony                uncletony.com\n",
       "3512        The Indian Garage             https://tigc.in/\n",
       "3513               Lipka Home       https://lipkahome.com/\n",
       "3514              NestInPeace  https://www.nestinpeace.in/\n",
       "\n",
       "[3515 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('testing_pipeline_merchants.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10be21b",
   "metadata": {},
   "source": [
    "### Here you can put your file name and then it will do the rest. The counter displays : for how many website , we got the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c337a72f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "Exception occurred for URL https://sircorbett.com: HTTPSConnectionPool(host='sircorbett.com', port=443): Max retries exceeded with url: / (Caused by SSLError(CertificateError(\"hostname 'sircorbett.com' doesn't match either of '*.myshopify.com', 'myshopify.com'\")))\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "df = getting_payment_info('yourfilename.csv') # give the csv file name "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5e04b3",
   "metadata": {},
   "source": [
    "### print your dataframe and you save it as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4425db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>website</th>\n",
       "      <th>payment_method_available_possible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Suger candy</td>\n",
       "      <td>https://sugercandy.com</td>\n",
       "      <td>[Zecpe]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Radha Mohan Enterprises</td>\n",
       "      <td>https://sircorbett.com</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PinkWoolf</td>\n",
       "      <td>https://pinkwoolf.com</td>\n",
       "      <td>[Simpl]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shriya Singhi Label</td>\n",
       "      <td>https://shriyasinghi.com</td>\n",
       "      <td>[Simpl]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISU</td>\n",
       "      <td>https://isufashion.com</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CSC by Jai Ingredients</td>\n",
       "      <td>https://teamcsc.in</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Santhitham</td>\n",
       "      <td>https://santhitham.shop</td>\n",
       "      <td>[Simpl]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BLUE BREW</td>\n",
       "      <td>https://bluebrew.in</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dromen and Co</td>\n",
       "      <td>https://dromenco.com</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OFFO Store</td>\n",
       "      <td>https://offostore.com</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Polite Society Shop</td>\n",
       "      <td>https://politesocietyshop.com</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Pink Supply</td>\n",
       "      <td>https://pinksupply.in</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Jumping Fences</td>\n",
       "      <td>https://jumpingfences.in</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The Cosmic Aroma</td>\n",
       "      <td>https://thecosmicaroma.in</td>\n",
       "      <td>[Razorpay Magic]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BHAVIKSHAH</td>\n",
       "      <td>https://studiobhavikshah.com</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Name                        website  \\\n",
       "0               Suger candy         https://sugercandy.com   \n",
       "1   Radha Mohan Enterprises         https://sircorbett.com   \n",
       "2                 PinkWoolf          https://pinkwoolf.com   \n",
       "3       Shriya Singhi Label       https://shriyasinghi.com   \n",
       "4                       ISU         https://isufashion.com   \n",
       "5    CSC by Jai Ingredients             https://teamcsc.in   \n",
       "6                Santhitham        https://santhitham.shop   \n",
       "7                 BLUE BREW            https://bluebrew.in   \n",
       "8             Dromen and Co           https://dromenco.com   \n",
       "9                OFFO Store          https://offostore.com   \n",
       "10      Polite Society Shop  https://politesocietyshop.com   \n",
       "11              Pink Supply          https://pinksupply.in   \n",
       "12           Jumping Fences       https://jumpingfences.in   \n",
       "13         The Cosmic Aroma      https://thecosmicaroma.in   \n",
       "14               BHAVIKSHAH   https://studiobhavikshah.com   \n",
       "\n",
       "   payment_method_available_possible  \n",
       "0                            [Zecpe]  \n",
       "1                                 []  \n",
       "2                            [Simpl]  \n",
       "3                            [Simpl]  \n",
       "4                                 []  \n",
       "5                                 []  \n",
       "6                            [Simpl]  \n",
       "7                                 []  \n",
       "8                                 []  \n",
       "9                                 []  \n",
       "10                                []  \n",
       "11                                []  \n",
       "12                                []  \n",
       "13                  [Razorpay Magic]  \n",
       "14                                []  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print your dataframe/csv file\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f539770",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to save your csv file\n",
    "df.to_csv('file_name.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e684f92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
